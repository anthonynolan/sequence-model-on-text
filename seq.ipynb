{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T09:57:01.858227Z",
     "start_time": "2020-09-16T09:57:01.769061Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob2\n",
    "from nltk import PorterStemmer, word_tokenize, FreqDist\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up variables\n",
    "\n",
    "unknown_word_token = '<UNK>'\n",
    "context_size = 2\n",
    "\n",
    "porterStemmer = PorterStemmer()\n",
    "\n",
    "minimum_frequency = 10\n",
    "\n",
    "data_dir='data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T09:50:17.062013Z",
     "start_time": "2020-09-16T09:50:17.058614Z"
    }
   },
   "outputs": [],
   "source": [
    "# define functions\n",
    "\n",
    "def read_corpus(titles=None):\n",
    "    if not titles:\n",
    "        files = glob2.glob(data_dir+'*')\n",
    "    else:\n",
    "        files = []\n",
    "        for title in titles:\n",
    "            files.append(data_dir+title)\n",
    "    print(files)\n",
    "\n",
    "    content = ''\n",
    "    for file in files:\n",
    "        with open(file, 'rt', encoding='utf-8-sig') as f:\n",
    "            content += f.read()\n",
    "    return content\n",
    "\n",
    "\n",
    "def process(st):\n",
    "    strip_chars = ['\\'']\n",
    "    for c in strip_chars:\n",
    "        st = st.replace(c , '')\n",
    "\n",
    "    rep_with_space_chars = [',', '.', '!', '?', '\"', '-', ';', '(', ')']\n",
    "    for c in rep_with_space_chars:\n",
    "        st = st.replace(c , ' ')\n",
    "\n",
    "    word_list = word_tokenize(st)\n",
    "    word_list = [porterStemmer.stem(a.lower().strip()) for a in word_list]\n",
    "    return word_list\n",
    "\n",
    "\n",
    "def replace_uncommon_words(words):    \n",
    "    most_common_count = len({k:v for k, v in FreqDist(words).items() if v>minimum_frequency})\n",
    "    c = Counter(words)\n",
    "    most_common = [pair[0] for pair in c.most_common(most_common_count)]\n",
    "    return [word if word in most_common else unknown_word_token for word in words]\n",
    "\n",
    "\n",
    "def create_word_indices(words):\n",
    "    vocab = set(words)\n",
    "    index_to_word = {k:v for k, v in enumerate(vocab)}\n",
    "    word_to_index = {v:k for k, v in index_to_word.items()}; \n",
    "    return index_to_word, word_to_index, vocab\n",
    "\n",
    "\n",
    "def convert_window(words_with_unk):\n",
    "    examples = []\n",
    "    for a in range(context_size, len(words_with_unk)-context_size):\n",
    "        examples.append([item for sublist in [words_with_unk[a-context_size:a], words_with_unk[a+1:a+context_size+1], [words_with_unk[a]]] for item in sublist])\n",
    "    return examples\n",
    "\n",
    "\n",
    "def split_data(X, Y):\n",
    "    X_train_incl_val, X_test, Y_train_incl_val, Y_test = train_test_split(X, Y)\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X_train_incl_val, Y_train_incl_val)\n",
    "    return X_train, X_val, X_test, Y_train, Y_val, Y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-16T09:51:10.570916Z",
     "start_time": "2020-09-16T09:51:10.560569Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/bleak.txt']\n",
      "1941579\n"
     ]
    }
   ],
   "source": [
    "# Execution section\n",
    "corpus = read_corpus(['bleak.txt'])\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"BLEAK HOUSE\\n\\nby\\n\\nCHARLES DICKENS\\n\\n\\n\\n\\n\\nCONTENTS\\n\\n            Preface\\n         I. In Chancery\\n        II. In Fashion\\n       III. A Progress\\n        IV. Telescopic Philanthropy\\n         V. A Morning Adventure\\n        VI. Quite at Home\\n       VII. The Ghost's Walk\\n      VIII. Covering a Multitude of Sins\\n        IX. Signs and Tokens\\n         X. The Law-Writer\\n        XI. Our Dear Brother\\n       XII. On the Watch\\n      XIII. Esther's Narrative\\n       XIV. Deportment\\n        XV. Bell Yard\\n       XVI. Tom-all-Alone's\\n      XVII. Esther's Narrative\\n     XVIII. Lady Dedlock\\n       XIX. Moving On\\n        XX. A New Lodger\\n       XXI. The Smallweed Family\\n      XXII. Mr. Bucket\\n     XXIII. Esther's Narrative\\n      XXIV. An Appeal Case\\n       XXV. Mrs. Snagsby Sees It All\\n      XXVI. Sharpshooters\\n     XXVII. More Old Soldiers Than One\\n    XXVIII. The Ironmaster\\n      XXIX. The Young Man\\n       XXX. Esther's Narrative\\n      XXXI. Nurse and Patient\\n     XXXII. The Appointed Time\\n    XXXIII. Interlop\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bleak',\n",
       " 'hous',\n",
       " 'by',\n",
       " 'charl',\n",
       " 'dicken',\n",
       " 'content',\n",
       " 'prefac',\n",
       " 'i',\n",
       " 'in',\n",
       " 'chanceri']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = process(corpus)\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bleak', 'hous', 'by', '<UNK>', '<UNK>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_with_unk = replace_uncommon_words(words)\n",
    "words_with_unk[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word, word_to_index, vocab = create_word_indices(words_with_unk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2300"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['bleak', 'hous', '<UNK>', '<UNK>', 'by'],\n",
       " ['hous', 'by', '<UNK>', 'content', '<UNK>'],\n",
       " ['by', '<UNK>', 'content', '<UNK>', '<UNK>'],\n",
       " ['<UNK>', '<UNK>', '<UNK>', 'i', 'content'],\n",
       " ['<UNK>', 'content', 'i', 'in', '<UNK>'],\n",
       " ['content', '<UNK>', 'in', 'chanceri', 'i'],\n",
       " ['<UNK>', 'i', 'chanceri', '<UNK>', 'in'],\n",
       " ['i', 'in', '<UNK>', 'in', 'chanceri'],\n",
       " ['in', 'chanceri', 'in', 'fashion', '<UNK>'],\n",
       " ['chanceri', '<UNK>', 'fashion', '<UNK>', 'in']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = convert_window(words_with_unk)\n",
    "examples[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_word_data_to_numbers(input):\n",
    "    Xs = []\n",
    "    Ys = []\n",
    "    for row in input:\n",
    "        Xs.append([word_to_index[word] for word in row[:-1]])\n",
    "        Ys.append([word_to_index[word] for word in row[-1:]])\n",
    "\n",
    "    X = np.vstack(Xs)\n",
    "    Y = np.vstack(Ys)\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = convert_word_data_to_numbers(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2179, 2059, 1188, 1188],\n",
       "       [2059,  162, 1188, 1715],\n",
       "       [ 162, 1188, 1715, 1188],\n",
       "       [1188, 1188, 1188, 1967],\n",
       "       [1188, 1715, 1967,  842]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 162],\n",
       "       [1188],\n",
       "       [1188],\n",
       "       [1715],\n",
       "       [1188]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, Y_train, Y_val, Y_test =  split_data(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras RNN [documentation](https://keras.io/guides/working_with_rnns/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
