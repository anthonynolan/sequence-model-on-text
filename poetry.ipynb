{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aachenosaurus\\naardonyx\\nabelisaurus\\nabrictosaurus\\nabrosaurus\\nabydosaurus\\nacantholipan\\nacanthopholis\\na'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_poem():\n",
    "    with open('data/dino.txt', 'rt') as f:\n",
    "        text = f.read()\n",
    "        return text\n",
    "\n",
    "poem = read_poem()\n",
    "poem[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "processed_text = [w.translate(table) for w in poem.split()]\n",
    "processed_text = [w.lower() for w in processed_text]\n",
    "processed_text = [w for w in processed_text if w.isalpha()]\n",
    "\n",
    "processed_text = ' '.join(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 10\n",
    "sequences = []\n",
    "for a in range(length, len(processed_text)):\n",
    "    sequences.append(processed_text[a-length:a+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aachenosaur', 'achenosauru', 'chenosaurus', 'henosaurus ', 'enosaurus a']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19644"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_char = dict(enumerate(sorted(set(''.join(sequences)))))\n",
    "char_to_index = {v:k for k,v in index_to_char.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences2 = []\n",
    "for row in sequences:\n",
    "    new_row = [char_to_index[c] for c in row]\n",
    "    sequences2.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 3, 8, 5, 14, 15, 19, 1, 21, 18],\n",
       " [1, 3, 8, 5, 14, 15, 19, 1, 21, 18, 21],\n",
       " [3, 8, 5, 14, 15, 19, 1, 21, 18, 21, 19],\n",
       " [8, 5, 14, 15, 19, 1, 21, 18, 21, 19, 0],\n",
       " [5, 14, 15, 19, 1, 21, 18, 21, 19, 0, 1],\n",
       " [14, 15, 19, 1, 21, 18, 21, 19, 0, 1, 1],\n",
       " [15, 19, 1, 21, 18, 21, 19, 0, 1, 1, 18],\n",
       " [19, 1, 21, 18, 21, 19, 0, 1, 1, 18, 4],\n",
       " [1, 21, 18, 21, 19, 0, 1, 1, 18, 4, 15],\n",
       " [21, 18, 21, 19, 0, 1, 1, 18, 4, 15, 14]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(index_to_char)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences2)[:, :-1]\n",
    "Y = np.array(sequences2)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1,  1,  3,  8,  5, 14, 15, 19,  1, 21],\n",
       "        [ 1,  3,  8,  5, 14, 15, 19,  1, 21, 18],\n",
       "        [ 3,  8,  5, 14, 15, 19,  1, 21, 18, 21]]),\n",
       " array([18, 21, 19]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:3], Y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19644, 10)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19644, 10, 27), (19644, 27))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = to_categorical(Y, num_classes=vocab_size)\n",
    "X = to_categorical(X, num_classes=vocab_size)\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.LSTM(units=75, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(layers.Dense(vocab_size, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "307/307 - 2s - loss: 0.9870 - accuracy: 0.7049\n",
      "Epoch 2/100\n",
      "307/307 - 2s - loss: 0.9733 - accuracy: 0.7083\n",
      "Epoch 3/100\n",
      "307/307 - 2s - loss: 0.9603 - accuracy: 0.7117\n",
      "Epoch 4/100\n",
      "307/307 - 2s - loss: 0.9471 - accuracy: 0.7159\n",
      "Epoch 5/100\n",
      "307/307 - 2s - loss: 0.9356 - accuracy: 0.7190\n",
      "Epoch 6/100\n",
      "307/307 - 2s - loss: 0.9221 - accuracy: 0.7287\n",
      "Epoch 7/100\n",
      "307/307 - 2s - loss: 0.9116 - accuracy: 0.7286\n",
      "Epoch 8/100\n",
      "307/307 - 2s - loss: 0.9001 - accuracy: 0.7321\n",
      "Epoch 9/100\n",
      "307/307 - 2s - loss: 0.8872 - accuracy: 0.7350\n",
      "Epoch 10/100\n",
      "307/307 - 2s - loss: 0.8755 - accuracy: 0.7402\n",
      "Epoch 11/100\n",
      "307/307 - 2s - loss: 0.8634 - accuracy: 0.7416\n",
      "Epoch 12/100\n",
      "307/307 - 2s - loss: 0.8515 - accuracy: 0.7465\n",
      "Epoch 13/100\n",
      "307/307 - 2s - loss: 0.8421 - accuracy: 0.7505\n",
      "Epoch 14/100\n",
      "307/307 - 2s - loss: 0.8298 - accuracy: 0.7552\n",
      "Epoch 15/100\n",
      "307/307 - 2s - loss: 0.8177 - accuracy: 0.7589\n",
      "Epoch 16/100\n",
      "307/307 - 2s - loss: 0.8071 - accuracy: 0.7585\n",
      "Epoch 17/100\n",
      "307/307 - 2s - loss: 0.7975 - accuracy: 0.7658\n",
      "Epoch 18/100\n",
      "307/307 - 2s - loss: 0.7876 - accuracy: 0.7707\n",
      "Epoch 19/100\n",
      "307/307 - 2s - loss: 0.7763 - accuracy: 0.7682\n",
      "Epoch 20/100\n",
      "307/307 - 2s - loss: 0.7672 - accuracy: 0.7744\n",
      "Epoch 21/100\n",
      "307/307 - 2s - loss: 0.7559 - accuracy: 0.7789\n",
      "Epoch 22/100\n",
      "307/307 - 2s - loss: 0.7460 - accuracy: 0.7828\n",
      "Epoch 23/100\n",
      "307/307 - 2s - loss: 0.7372 - accuracy: 0.7844\n",
      "Epoch 24/100\n",
      "307/307 - 2s - loss: 0.7258 - accuracy: 0.7903\n",
      "Epoch 25/100\n",
      "307/307 - 2s - loss: 0.7184 - accuracy: 0.7911\n",
      "Epoch 26/100\n",
      "307/307 - 2s - loss: 0.7095 - accuracy: 0.7932\n",
      "Epoch 27/100\n",
      "307/307 - 2s - loss: 0.7018 - accuracy: 0.7975\n",
      "Epoch 28/100\n",
      "307/307 - 2s - loss: 0.6938 - accuracy: 0.8007\n",
      "Epoch 29/100\n",
      "307/307 - 2s - loss: 0.6842 - accuracy: 0.8038\n",
      "Epoch 30/100\n",
      "307/307 - 2s - loss: 0.6757 - accuracy: 0.8063\n",
      "Epoch 31/100\n",
      "307/307 - 2s - loss: 0.6654 - accuracy: 0.8089\n",
      "Epoch 32/100\n",
      "307/307 - 2s - loss: 0.6591 - accuracy: 0.8117\n",
      "Epoch 33/100\n",
      "307/307 - 2s - loss: 0.6502 - accuracy: 0.8143\n",
      "Epoch 34/100\n",
      "307/307 - 2s - loss: 0.6452 - accuracy: 0.8152\n",
      "Epoch 35/100\n",
      "307/307 - 2s - loss: 0.6383 - accuracy: 0.8163\n",
      "Epoch 36/100\n",
      "307/307 - 2s - loss: 0.6289 - accuracy: 0.8195\n",
      "Epoch 37/100\n",
      "307/307 - 2s - loss: 0.6212 - accuracy: 0.8232\n",
      "Epoch 38/100\n",
      "307/307 - 2s - loss: 0.6116 - accuracy: 0.8260\n",
      "Epoch 39/100\n",
      "307/307 - 2s - loss: 0.6085 - accuracy: 0.8284\n",
      "Epoch 40/100\n",
      "307/307 - 2s - loss: 0.6012 - accuracy: 0.8299\n",
      "Epoch 41/100\n",
      "307/307 - 2s - loss: 0.5930 - accuracy: 0.8313\n",
      "Epoch 42/100\n",
      "307/307 - 2s - loss: 0.5847 - accuracy: 0.8342\n",
      "Epoch 43/100\n",
      "307/307 - 2s - loss: 0.5821 - accuracy: 0.8339\n",
      "Epoch 44/100\n",
      "307/307 - 2s - loss: 0.5730 - accuracy: 0.8359\n",
      "Epoch 45/100\n",
      "307/307 - 2s - loss: 0.5683 - accuracy: 0.8380\n",
      "Epoch 46/100\n",
      "307/307 - 2s - loss: 0.5632 - accuracy: 0.8394\n",
      "Epoch 47/100\n",
      "307/307 - 2s - loss: 0.5544 - accuracy: 0.8443\n",
      "Epoch 48/100\n",
      "307/307 - 2s - loss: 0.5478 - accuracy: 0.8447\n",
      "Epoch 49/100\n",
      "307/307 - 2s - loss: 0.5429 - accuracy: 0.8457\n",
      "Epoch 50/100\n",
      "307/307 - 2s - loss: 0.5380 - accuracy: 0.8478\n",
      "Epoch 51/100\n",
      "307/307 - 2s - loss: 0.5321 - accuracy: 0.8501\n",
      "Epoch 52/100\n",
      "307/307 - 2s - loss: 0.5248 - accuracy: 0.8507\n",
      "Epoch 53/100\n",
      "307/307 - 2s - loss: 0.5219 - accuracy: 0.8517\n",
      "Epoch 54/100\n",
      "307/307 - 2s - loss: 0.5164 - accuracy: 0.8551\n",
      "Epoch 55/100\n",
      "307/307 - 2s - loss: 0.5126 - accuracy: 0.8559\n",
      "Epoch 56/100\n",
      "307/307 - 2s - loss: 0.5077 - accuracy: 0.8577\n",
      "Epoch 57/100\n",
      "307/307 - 2s - loss: 0.5030 - accuracy: 0.8575\n",
      "Epoch 58/100\n",
      "307/307 - 2s - loss: 0.4978 - accuracy: 0.8579\n",
      "Epoch 59/100\n",
      "307/307 - 2s - loss: 0.4896 - accuracy: 0.8623\n",
      "Epoch 60/100\n",
      "307/307 - 2s - loss: 0.4888 - accuracy: 0.8625\n",
      "Epoch 61/100\n",
      "307/307 - 2s - loss: 0.4841 - accuracy: 0.8634\n",
      "Epoch 62/100\n",
      "307/307 - 2s - loss: 0.4791 - accuracy: 0.8643\n",
      "Epoch 63/100\n",
      "307/307 - 2s - loss: 0.4727 - accuracy: 0.8671\n",
      "Epoch 64/100\n",
      "307/307 - 2s - loss: 0.4709 - accuracy: 0.8659\n",
      "Epoch 65/100\n",
      "307/307 - 2s - loss: 0.4659 - accuracy: 0.8698\n",
      "Epoch 66/100\n",
      "307/307 - 2s - loss: 0.4614 - accuracy: 0.8711\n",
      "Epoch 67/100\n",
      "307/307 - 2s - loss: 0.4555 - accuracy: 0.8732\n",
      "Epoch 68/100\n",
      "307/307 - 2s - loss: 0.4529 - accuracy: 0.8711\n",
      "Epoch 69/100\n",
      "307/307 - 2s - loss: 0.4476 - accuracy: 0.8748\n",
      "Epoch 70/100\n",
      "307/307 - 2s - loss: 0.4439 - accuracy: 0.8740\n",
      "Epoch 71/100\n",
      "307/307 - 2s - loss: 0.4391 - accuracy: 0.8765\n",
      "Epoch 72/100\n",
      "307/307 - 2s - loss: 0.4399 - accuracy: 0.8742\n",
      "Epoch 73/100\n",
      "307/307 - 2s - loss: 0.4335 - accuracy: 0.8746\n",
      "Epoch 74/100\n",
      "307/307 - 2s - loss: 0.4293 - accuracy: 0.8775\n",
      "Epoch 75/100\n",
      "307/307 - 2s - loss: 0.4267 - accuracy: 0.8788\n",
      "Epoch 76/100\n",
      "307/307 - 2s - loss: 0.4230 - accuracy: 0.8785\n",
      "Epoch 77/100\n",
      "307/307 - 2s - loss: 0.4197 - accuracy: 0.8809\n",
      "Epoch 78/100\n",
      "307/307 - 2s - loss: 0.4175 - accuracy: 0.8818\n",
      "Epoch 79/100\n",
      "307/307 - 2s - loss: 0.4139 - accuracy: 0.8830\n",
      "Epoch 80/100\n",
      "307/307 - 2s - loss: 0.4091 - accuracy: 0.8832\n",
      "Epoch 81/100\n",
      "307/307 - 2s - loss: 0.4082 - accuracy: 0.8823\n",
      "Epoch 82/100\n",
      "307/307 - 2s - loss: 0.4039 - accuracy: 0.8855\n",
      "Epoch 83/100\n",
      "307/307 - 2s - loss: 0.4024 - accuracy: 0.8837\n",
      "Epoch 84/100\n",
      "307/307 - 2s - loss: 0.3978 - accuracy: 0.8870\n",
      "Epoch 85/100\n",
      "307/307 - 2s - loss: 0.3974 - accuracy: 0.8869\n",
      "Epoch 86/100\n",
      "307/307 - 2s - loss: 0.3905 - accuracy: 0.8883\n",
      "Epoch 87/100\n",
      "307/307 - 2s - loss: 0.3901 - accuracy: 0.8884\n",
      "Epoch 88/100\n",
      "307/307 - 2s - loss: 0.3868 - accuracy: 0.8883\n",
      "Epoch 89/100\n",
      "307/307 - 2s - loss: 0.3840 - accuracy: 0.8917\n",
      "Epoch 90/100\n",
      "307/307 - 2s - loss: 0.3823 - accuracy: 0.8913\n",
      "Epoch 91/100\n",
      "307/307 - 2s - loss: 0.3781 - accuracy: 0.8923\n",
      "Epoch 92/100\n",
      "307/307 - 2s - loss: 0.3728 - accuracy: 0.8920\n",
      "Epoch 93/100\n",
      "307/307 - 2s - loss: 0.3728 - accuracy: 0.8909\n",
      "Epoch 94/100\n",
      "307/307 - 2s - loss: 0.3721 - accuracy: 0.8924\n",
      "Epoch 95/100\n",
      "307/307 - 2s - loss: 0.3684 - accuracy: 0.8934\n",
      "Epoch 96/100\n",
      "307/307 - 2s - loss: 0.3664 - accuracy: 0.8945\n",
      "Epoch 97/100\n",
      "307/307 - 2s - loss: 0.3686 - accuracy: 0.8939\n",
      "Epoch 98/100\n",
      "307/307 - 2s - loss: 0.3633 - accuracy: 0.8940\n",
      "Epoch 99/100\n",
      "307/307 - 2s - loss: 0.3603 - accuracy: 0.8952\n",
      "Epoch 100/100\n",
      "307/307 - 2s - loss: 0.3571 - accuracy: 0.8967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1465bdfd0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, epochs=100, verbose=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aoifengosaurus'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_text(hint, num_to_gen):\n",
    "    in_text = hint\n",
    "    for a in range(num_to_gen):\n",
    "        char_to_add = index_to_char[model.predict_classes(to_categorical(pad_sequences([[char_to_index[c] for c in in_text]], maxlen=10, truncating='pre'), num_classes=vocab_size))[0]]\n",
    "        if char_to_add ==' ': break\n",
    "        in_text+=char_to_add\n",
    "    return in_text\n",
    "generate_text(hint = 'aoife', num_to_gen=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
